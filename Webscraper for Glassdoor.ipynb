{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Selenium Tutorial: \n",
    "# https://medium.com/@hoppy/\n",
    "# how-to-test-or-scrape-javascript-rendered-websites-with-python-selenium-a-beginner-step-by-c137892216aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_site = \"https://www.glassdoor.com/Job/\" +\\\n",
    "            \"jobs.htm?suggestCount=0&suggestChosen=false\" +\\\n",
    "            \"&clickSource=searchBtn&typedKeyword=data+scientist\" +\\\n",
    "            \"&sc.keyword=data+scientist&locT=&locId=&jobType=\"\n",
    "\n",
    "deloitte = \"https://www.glassdoor.com/Job/\" +\\\n",
    "           \"jobs.htm?suggestCount=0&suggestChosen=false\" +\\\n",
    "           \"&clickSource=searchBtn&typedKeyword=data+scientist+booz+allen+hamilton\" +\\\n",
    "           \"&sc.keyword=data+scientist+booz+allen+hamilton&locT=C&locId=1138213&jobType=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            print(resp)\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "    \n",
    "def is_good_response(resp):\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "def log_error(e):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-23b6d01bad85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_site\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "request.urlopen(test_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=data+scientist+booz+allen+hamilton&sc.keyword=data+scientist+booz+allen+hamilton&locT=C&locId=1138213&jobType='"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_html = simple_get(test_site)\n",
    "deloitte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# Create the link to load with webdriver\n",
    "def build_link(term, locT=\"\", locId=\"\", jobType=\"\"):\n",
    "    domain = \"https://www.glassdoor.com/Job/jobs.htm\"\n",
    "    header = \"?suggestCount=0&suggestChosen=false&clickSource=searchBtn&\"\n",
    "    query = \"typedKeyword={0}&sc.keyword={0}\".format(term.replace(\" \", \"+\"))\n",
    "    location = \"&locT{}=&locId{}=&jobType={}\".format(locT, locId, jobType)\n",
    "    return(domain + header + query + location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webdriver Downloads\n",
    "\n",
    "Downloads page on Selenium: https://www.seleniumhq.org/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Users/glenabastillas/Documents/BAH/Hackathon/Gender Parity/drivers/chromedriver\"\n",
    "firefoxdriver = \"/Users/glenabastillas/Documents/BAH/Hackathon/Gender Parity/drivers/geckodriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=chromedriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(build_link('data scientist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"Glassdoor\" in driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_element_by_tag_name(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = \"//*[@class='jobDescriptionContent desc']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_element_by_xpath(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_attribute in module selenium.webdriver.remote.webelement:\n",
      "\n",
      "get_attribute(name) method of selenium.webdriver.remote.webelement.WebElement instance\n",
      "    Gets the given attribute or property of the element.\n",
      "    \n",
      "    This method will first try to return the value of a property with the\n",
      "    given name. If a property with that name doesn't exist, it returns the\n",
      "    value of the attribute with the same name. If there's no attribute with\n",
      "    that name, ``None`` is returned.\n",
      "    \n",
      "    Values which are considered truthy, that is equals \"true\" or \"false\",\n",
      "    are returned as booleans.  All other non-``None`` values are returned\n",
      "    as strings.  For attributes or properties which do not exist, ``None``\n",
      "    is returned.\n",
      "    \n",
      "    :Args:\n",
      "        - name - Name of the attribute/property to retrieve.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        # Check if the \"active\" CSS class is applied to an element.\n",
      "        is_active = \"active\" in target_element.get_attribute(\"class\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(elem.get_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice Looping through Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WebElement' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-364564daffaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"//*[@class='noPad']\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'WebElement' object is not iterable"
     ]
    }
   ],
   "source": [
    "xpath = \"//*[@class='noPad']\"\n",
    "for e in driver.find_element_by_xpath(xpath):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Work that matters, fueled by passion for pets! At Hill’s we have a purpose. Every day around the world, we transform the lives of millions of pet families through pioneering innovation, amazing nutrition, and the best and brightest people. Founded more than 75 years ago with an unwavering commitment to pet nutrition, Hills' mission is to help enrich and lengthen the special relationships between people and their pets.\",\n",
       " '',\n",
       " \"HILL'S® Prescription Diet® therapeutic pet foods, HILL'S® Science Diet® and HILL'S® Ideal Balance™ wellness pet foods are sold worldwide. Hill’s is a division of Colgate-Palmolive, a leading global consumer products company, tightly focused on Oral Care, Personal Care, Home Care and Pet Nutrition, with sales of products in more than 200 countries. To learn more about Hill's and Colgate, please visit http://www.hillspet.com and http://www.colgatepalmolive.com, or find us on LinkedIn, Facebook, Twitter and YouTube.\",\n",
       " '',\n",
       " 'Location: Topeka, Kansas, United States',\n",
       " 'Relocation Assistance Offered Within Country',\n",
       " '# 62547',\n",
       " '',\n",
       " ' ',\n",
       " 'Job Summary',\n",
       " '  The focus of the Data Scientist role is to analyze large amounts of complex raw and processed information to find patterns that will improve our understanding of the relationship between nutrition and health/wellbeing.',\n",
       " 'The individual will be responsible for modeling complex scientific problems, discovering insights and identifying opportunities through the use of statistical, algorithmic, mining and visualization techniques.',\n",
       " 'In addition to advanced analytic skills, s/he will also be proficient at integrating and preparing large, varied datasets, architecting specialized database and computing environments, and communicating results.',\n",
       " 'Should be highly analytical with solid expertise in analysis, math and statistics.',\n",
       " 'Critical thinking, creativity and problem-solving skills are essential for success in this role.',\n",
       " 'We also want to see experience and a passion for machine-learning and research.',\n",
       " 'Primary goal in this role will be to lead projects to identify patterns from structured and unstructured data to generate hypotheses for new nutritional products and matching existing and future products to optimal market segments.',\n",
       " 'Collaboration with researchers in project teams; timely delivery of results and clear communication are essential to success.',\n",
       " ' Education/ Experience Requirements',\n",
       " '  PhD in Computer Science, Engineering, Applied Math, Biology, Physics or relevant quantitative science field with at least 2 years of experience in data analysis/ data science role or MSc with at least 6 years of relevant experience in data science role.',\n",
       " ' Expected Areas of Skills',\n",
       " '  Proven experience as a Data Scientist or Data Analyst with data mining responsibilities',\n",
       " 'Demonstrated understanding of machine-learning approaches, preferably in context of biomedical/biological research',\n",
       " 'Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset',\n",
       " 'Experience using business intelligence tools (e.g. Tableau) and distributed data frameworks (e.g.',\n",
       " 'Hadoop)',\n",
       " 'Analytical mind and business acumen',\n",
       " 'Strong applied math skills',\n",
       " 'Problem-solving',\n",
       " 'Excellent written and oral communication and presentation skills',\n",
       " \"Are you interested in working for Hill's Pet Nutrition? You can apply to work with us using this online application. Attach all relevant documents such as a cover letter and resume or CV. Applications received by e-mail are not considered in the selection process.\",\n",
       " '',\n",
       " 'Become part of our team. We look forward to your application.',\n",
       " '',\n",
       " 'Equal Opportunity Employer',\n",
       " 'Colgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, or any other characteristic protected by law.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem.text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"CAF9C4CA-E353-4524-B7A5-25816053FD3D\", element=\"node-8041F5DB-3645-4D46-86FF-D351C352717E\")>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helperP3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2b8e9974d6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperP3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_glassdoor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchJobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_cleaner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_pause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helperP3'"
     ]
    }
   ],
   "source": [
    "# Import modules required to connect to the website with an API\n",
    "from selenium import webdriver\n",
    "#from bs4 import BeautifulSoup # For HTML parsing\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "from collections import Counter # Keep track of our term counts\n",
    "from nltk.corpus import stopwords # Filter out stopwords, such as 'the', 'or', 'and'\n",
    "import pandas as pd # For converting results to a dataframe and bar chart plots\n",
    "from selenium.webdriver.common import action_chains, keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "from helperP3 import load_obj, save_obj, init_glassdoor, searchJobs, text_cleaner, get_pause\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def glassdoorScrape(get_short = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Created on Tue Aug 16 22:41:30 2016\n",
    "    Scrape Glassdoor website using SELENIUM\n",
    "    @author: Diego De Lazzari\n",
    "    \"\"\"\n",
    "\n",
    "    # call the helper\n",
    "    \n",
    "    \n",
    "        # 1- Load existing dictionary. Check for initial dictionary. \n",
    "        # If empty initialize\n",
    "            \n",
    "    try:               \n",
    "        jobDict = load_obj('glassDoorDict')\n",
    "        link =    load_obj('glassDoorlink')\n",
    "    except:\n",
    "        save_obj([], 'glassDoorlink')\n",
    "        save_obj({}, 'glassDoorDict')\n",
    "        \n",
    "        jobDict = load_obj('glassDoorDict')\n",
    "        link =    load_obj('glassDoorlink')    \n",
    "    \n",
    "    # 2- Choose what you want to do: \n",
    "#        get_shot => Scraping for links, \n",
    "#        get_long => Scraping for data,\n",
    "\n",
    "\n",
    "    get_long = (not get_short)\n",
    "    \n",
    "    if get_short or get_long:\n",
    "        \n",
    "    # 3- initialize website, cities and jobs\n",
    "        \n",
    "        website = \"https://www.glassdoor.com/index.htm\"\n",
    "        \n",
    "        jobName_lst = ['Data Scientist', 'Data Analyst']\n",
    "        jobName = np.random.choice(jobName_lst)\n",
    "    \n",
    "        city_lst = ['San Jose','New York','San Francisco','Detroit','Washington','Austin','Boston','Los Angeles',' ']\n",
    "        city = np.random.choice(city_lst)        \n",
    "        \n",
    "        # Initialize the webdriver\n",
    "        \n",
    "        browser = init_glassdoor()  \n",
    "    \n",
    "    # 4- Scrape the short list or the links (when you ae done, both are false)\n",
    "    \n",
    "    \n",
    "    if get_short:\n",
    "    \n",
    "        browser.get(website)\n",
    "            \n",
    "        # search for jobs (short description) \n",
    "        try:    \n",
    "                    update_jobDict, update_link = searchJobs(jobName, city, jobDict, link)\n",
    "#                    sleep(get_pause())\n",
    "        except:\n",
    "            sys.exit(\"Error message\")\n",
    "            \n",
    "        # save dictionary and link     \n",
    "    \n",
    "        save_obj(update_jobDict, 'glassDoorDict')\n",
    "        save_obj(update_link, 'glassDoorlink')\n",
    "        \n",
    "     # 5- Scrape the job description, for every link\n",
    "                    \n",
    "    if get_long:        \n",
    "        \n",
    "        while len(link) > 0:\n",
    "            \n",
    "             \n",
    "            try:\n",
    "                rnd_job = np.random.choice(range(len(link)))\n",
    "                \n",
    "                ids = link[rnd_job][0]\n",
    "                page = link[rnd_job][1]\n",
    "                \n",
    "                browser.get(page)                 \n",
    "                sleep(3)\n",
    "                \n",
    "                # Extract text   //*[@id=\"JobDescContainer\"]/div[1]\n",
    "                desc_list = browser.find_element_by_xpath('//*[@id=\"JobDescContainer\"]/div[1]').text\n",
    "                description = text_cleaner(desc_list)\n",
    "                \n",
    "                # Update dictionary and remove succe\n",
    "                jobDict[ids].append(description)               \n",
    "                dummy=link.pop(rnd_job)\n",
    "                               \n",
    "                # if everything is fine, save\n",
    "                save_obj(jobDict, 'glassDoorDict')\n",
    "                save_obj(link, 'glassDoorlink')\n",
    "                                                \n",
    "                print( 'Scraped successfully ' + ids)\n",
    "                \n",
    "                sleep(get_pause())\n",
    "            except:   \n",
    "                print( ids + ' is not working! Sleep for 10 seconds and retry')\n",
    "                print( 'Still missing ' + str(len(link)) + ' links' )\n",
    "                sleep(8)\n",
    "                \n",
    "        browser.close()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
